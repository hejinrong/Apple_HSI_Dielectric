{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from mvlearn.embed import MCCA, KMCCA\n",
    "import numpy as np\n",
    "from mvlearn.compose import ViewTransformer, ConcatMerger\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 使用RandomOverSampler从少数类的样本中进行随机采样来增加新的样本使各个分类均衡\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# 通过插值生成新的样本,生成靠近在KNN中被分类错误的原样本。\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# SMOTE: 对于少数类样本a, 随机选择一个最近邻的样本b, 然后从a与b的连线上随机选取一个点c作为新的少数类样本\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras import models\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"D:\\WorkSpace\\DataSets\\To石延新-苹果检测光电数据\\何进荣处理后的数据\\HSI_Dielectric_Data.mat\"\n",
    "data = loadmat(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#  standartize\n",
    "def standartizeData(X):\n",
    "    #newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    scaler = preprocessing.MinMaxScaler().fit(X)  \n",
    "    newX = scaler.transform(X)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1]))\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Label']\n",
    "Xs0 = standartizeData(data[\"Data2\"].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_smote, y_resampled_smote = SMOTE().fit_sample(Xs0, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "Sensitive = []\n",
    "Specificity = []\n",
    "Precision = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    for train, test in kfold.split(X_resampled_smote, y_resampled_smote):\n",
    "        \n",
    "        stand_means = preprocessing.MinMaxScaler()\n",
    "        \n",
    "        # 训练集\n",
    "        X_train = X_resampled_smote[train]\n",
    "        Xtrain = stand_means.fit_transform(X_train)\n",
    "        \n",
    "        clf = KNeighborsClassifier(3)\n",
    "        #clf = SVC(kernel=\"poly\", degree = 3)\n",
    "#         model = models.Sequential()\n",
    "#         model.add(Dense(128, input_shape=(Xs0.shape[1],), kernel_regularizer=regularizers.l2(0.0001),))\n",
    "#         model.add(layers.LeakyReLU(alpha=0.1))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(64, kernel_regularizer=regularizers.l2(0.0001),))\n",
    "#         model.add(layers.LeakyReLU(alpha=0.1))\n",
    "#         model.add(Dropout(0.3))\n",
    "# # #         model.add(Dense(256, kernel_regularizer=regularizers.l2(0.0001),))\n",
    "# # #         model.add(layers.LeakyReLU(alpha=0.1))\n",
    "# # #         model.add(Dropout(0.1))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#         model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "        clf.fit(Xtrain, y_resampled_smote[train])\n",
    "        \n",
    "        # 测试集\n",
    "        X_test = X_resampled_smote[test]\n",
    "        Xtest = stand_means.transform(X_test)\n",
    "         \n",
    "        predictions = clf.predict(Xtest)\n",
    "        precisions, recall, f1score, _ = metrics.precision_recall_fscore_support(y_resampled_smote[test], predictions.round())\n",
    "\n",
    "        Sensitive.append(precisions[0])\n",
    "        Specificity.append(precisions[1])\n",
    "        Precision.append(recall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灵敏度：0.9679±0.0270\n",
      "特异度：0.7652±0.0346\n",
      "精度：0.6977±0.0587\n",
      "灵敏度_标准差: 0.0270\n"
     ]
    }
   ],
   "source": [
    "print(\"灵敏度：{:.4f}±{:.4f}\".format(np.mean(Sensitive), np.std(Sensitive)))\n",
    "print(\"特异度：{:.4f}±{:.4f}\".format(np.mean(Specificity), np.std(Specificity)))\n",
    "print(\"精度：{:.4f}±{:.4f}\".format(np.mean(Precision), np.std(Precision)))\n",
    "print(\"灵敏度_标准差: %.4f\"%np.std(Sensitive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
